<!DOCTYPE html>
<html lang="en">
  <head>
<meta charset="utf-8" />
<meta
  name="viewport"
  content="width=device-width, initial-scale=1.0, maximum-scale=1.0"
/>
<meta
  name="description"
  content="Design and implement your programming language and software analysis tools with mathematical rigor."
/>
<meta name="keywords" content="runtime, verification, rv, k" />
<meta name="author" content="RV-Toolkit | Runtime Verification Inc" />
<meta name="robots" content="index, follow" />
<link rel="canonical" href="https://runtimeverification.github.io/rv-toolkit-docs/match/benchmark/" />

<!--favicon icon-->
<link rel="icon" type="image/png" href="../../assets/img/favicon.ico" />

<title>RV-Toolkit | Runtime Verification Inc</title>

<!-- <base href="/k/" /> -->

<!--web fonts-->
<link
  href="https://fonts.googleapis.com/css?family=Nunito:300,400,600,700,800"
  rel="stylesheet"
/>
<link
  href="https://fonts.googleapis.com/css?family=Lora:400i"
  rel="stylesheet"
/>

<link
  href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css"
  rel="stylesheet"
/>

<link href="../../assets/css/index.css" rel="stylesheet" />

<!--[if (gt IE 9) |!(IE)]><!-->
<!--<link rel="stylesheet" href="/assets/vendor/custom-nav/css/effects/fade-menu.css"/>-->
<!-- <link rel="stylesheet" href="../../assets/k/vl-nav/css/effects/slide-menu.css" /> -->
<!--<![endif]-->

  </head>

  <body>
<header
  class="navbar navbar-expand navbar-dark flex-column flex-md-row bd-navbar"
>
  <a class="logo-link" href="../../index.html"> RV-Toolkit </a>
  <ul class="navbar-nav ml-md-auto">
    <li class="nav-item">
      <a
        class="nav-link pl-2 pr-1 mx-1 py-3 my-n2"
        href="https://github.com/runtimeverification/rv-toolkit-docs"
        target="_blank"
        rel="noopener"
        aria-label="GitHub"
      >
        <i class="fab fa-github"></i>
      </a>
    </li>
  </ul>
  <!--
  <a
    class="btn btn-rv-blue d-none d-lg-inline-block mb-3 mb-md-0 ml-md-3"
    href="../../downloads"
    >Download</a
  >
  -->
</header>


    <div class="container-fluid">
      <div class="row flex-xl-nowrap">
<div class="col-12 col-md-3 col-xl-2 bd-sidebar mb-3">
    <form
      role="search"
      class="bd-search d-flex align-items-center justify-content-between"
    >
      <input
        type="search"
        class="form-control"
        placeholder="Search..."
        aria-label="Search for..."
        autocomplete="false"
        id="search-box"
      />
      <button
        class="btn bd-search-docs-toggle d-md-none p-0 ml-3 collapsed"
        type="button"
        aria-label="Toggle docs navigation"
        style="font-size: 1.4rem"
      >
        <i class="fas fa-bars"></i>
      </button>
    </form>
    <nav class="collapse bd-links" aria-label="Main navigation">
      <div class="bd-toc-item">
        <a class="bd-toc-link" href="../../match/">Welcome!</a>
        <a class="bd-toc-link" href="../../match/installing/">Installing</a>
        <a class="bd-toc-link" href="../../match/quickstart/">Quickstart</a>
        <a class="bd-toc-link" href="../../match/vagrant/"
          >Running Vagrant VM</a
        >
        <a class="bd-toc-link" href="../../match/runningexamples/"
          >Running Examples</a
        >
        <a class="bd-toc-link" href="../../match/benchmark/"
          >Toyota ITC Benchmark</a
        >
        <a class="bd-toc-link" href="../../match/eclipse/"
          >Eclipse Integration</a
        >
        <a class="bd-toc-link" href="../../match/reporting/"
          >Creating Error Reports</a
        >
        <a class="bd-toc-link" href="../../match/troubleshooting/"
          >Problems running RV-Match?</a
        >
        <a
          class="bd-toc-link"
          href="https://runtimeverification.com/blog/category/rv-match/"
          target="_blank"
          >RV-Match Blog</a
        >
      </div>
    </nav>
  </div>
  
        <main
          class="col-12 col-md-6 col-xl-8 py-md-3 pl-md-5 bd-content"
          role="main"
        >
          <div class="introduction markdown-preview"><html><head></head><body><h1 id="toyota-itc-benchmark">Toyota ITC Benchmark</h1>
<p>One of the applications you can use to demonstrate the capabilities of RV-Match is the benchmark generated by Toyota ITC to evaluate different static analysis tools. For more information on this benchmark, refer to the following ISSRE‘15 paper:</p>
<blockquote>
<p>Shinichi Shiraishi, Veena Mohan, and Hemalatha Marimuthu. 2015. <a href="https://www.researchgate.net/publication/283548090_Test_Suites_for_Benchmarks_of_Static_Analysis_Tools" target="_blank" rel="noreferrer noopener">Test Suites for Benchmarks of Static Analysis Tools</a>. In Proceedings of the 26th IEEE International Symposium on Software Reliability Engineering (<a href="http://issre.net/indtrack" target="_blank" rel="noreferrer noopener">ISSRE‘15</a>).</p>
</blockquote>
<p>The Toyota ITC benchmark is publicly available <a href="https://github.com/regehr/itc-benchmarks/" target="_blank" rel="noreferrer noopener">on Github</a>. At the time of this writing (December 2015), it consisted of a total of 1,276 tests, half with planted defects meant to evaluate the defect rate (DR) capability of the analysis tools and the other half without defects meant to evaluate their false positive rate. The tests are grouped in nine different categories: static memory, dynamic memory, stack-related, numerical, resource management, pointer-related, concurrency, inappropriate code, and miscellaneous.</p>
<h2 id="the-disappearing-2014-paper">The Disappearing 2014 Paper</h2>
<p>An early 2014 version of the paper above, <a href="http://dx.doi.org/10.1109/ISSREW.2014.62" target="_blank" rel="noreferrer noopener">Quantitative Evaluation of Static Analysis Tools</a>, was presented and published in the same avenue one year before, namely in <a href="http://2014.issre.net/industry-papers.html" target="_blank" rel="noreferrer noopener">ISSRE‘14</a>. However, the 2014 paper has been removed from the IEEE database and we are not able to find it anywhere anymore. According to <a href="http://blog.regehr.org/archives/1217" target="_blank" rel="noreferrer noopener">Prof. Regehr’s Blog</a>, Coverity has a <a href="http://sqlmag.com/sql-server/devils-dewitt-clause" target="_blank" rel="noreferrer noopener">DeWitt Clause</a> in their EULA that disallows comparisons of their tool with other tools, which is probably the reason why the 2014 paper was removed.</p>
<p>Although the ISSRE‘14 paper itself is not available anymore, some articles about it have survived on the Internet, such as <a href="http://www.embedded.com/electronics-blogs/cole-bin/4440131/How-Toyota-evaluates-static-analysis-tools" target="_blank" rel="noreferrer noopener">How Toyota Evaluates Static Analysis Tools</a> and <a href="http://www.prnewswire.com/news-releases/independent-study-names-codesonar-best-in-class-after-head-to-head-comparison-300035357.html" target="_blank" rel="noreferrer noopener">Independent Study Names CodeSonar Best in Class after Head-to-Head Comparison</a>. From these articles we learn that Toyota ITC has evaluated six different static analysis tools against their benchmark, and that GrammaTech’s CodeSonar was ranked overall the best among them.</p>
<p>The revised version of the Toyota ITC paper published in <a href="https://www.researchgate.net/publication/283548090_Test_Suites_for_Benchmarks_of_Static_Analysis_Tools" target="_blank" rel="noreferrer noopener">ISSRE‘15</a> discusses, with approval from GrammaTech and MathWorks, only three static analysis tools: GrammaTech’s CodeSonar and MathWorks’ Code Prover and Bug Finder. Kudos to the Toyota ITC researchers for their fabulous and immensely useful effort, and to Grammatech and MathWorks for allowing science to follow its path!</p>
<h2 id="running-rv-match-on-the-toyota-itc-benchmark">Running RV-Match on the Toyota ITC Benchmark</h2>
<p>When executed on the Toyota ITC benchmark, RV-Match scores the best of any of the tools for which we were able to obtain scores. RV-Match also distinguishes itself by having a perfect false positive rate of 0 false positives. The table below shows how RV-Match compares (in January 2016) to the commercial static analysis tools discussed in the <a href="https://www.researchgate.net/publication/283548090_Test_Suites_for_Benchmarks_of_Static_Analysis_Tools" target="_blank" rel="noreferrer noopener">ISSRE‘15</a> paper:</p>
<p><img src="https://user-images.githubusercontent.com/1908863/108987782-a3e58280-76ce-11eb-9006-2d4ef0fc1f36.png" alt="benchmark"></p>
<p><em>DR</em> (Defect Rate) refers to the percentage of tests containing errors where the error was detected. <em>FPR</em> (False Positive Rate) refers to the percentage of tests not containing errors where a false positive was detected, and underlined <em>FPR</em> is 100 - <em>FPR</em>. <em>PM</em> refers to the productivity metric computed in the paper, which is geometric mean of <em>DR</em> and 100 - <em>FPR</em>. For the other tools referenced in the table above, we used the numbers presented in the original public <a href="https://www.researchgate.net/publication/283548090_Test_Suites_for_Benchmarks_of_Static_Analysis_Tools" target="_blank" rel="noreferrer noopener">ISSRE‘15</a> paper above by Toyota ITC, because these tools are not freely available. The green boxes mean that tool had the best score in that category for that metric. The red highlights are features not yet supported by the corresponding tool, yielding a 0 score. The dark red boxes at the bottom compare the final score of RV-Match to that of the best tool in the original ISSRE‘15 paper.</p>
<p>Usual compilers also perform some minimal static checks on the program. For reference, in the table above we also included the numbers we obtained with <code>gcc</code> and <code>clang</code> when run on the benchmark, with all their warning flags enabled. Therefore, as illustrated in the table, if no special analysis tools are used in your development process, you should expect your usual compiler to only catch about 5% of the undefinedness C bugs lurking in your code. Which is why it is very rarely the case that safety critical code is developed without the help of software analysis tools. There is also a variety of non-commercial analysis tools that you can use to improve the quality of your code. Below is a table showing the numbers we obtained (in January 2016) when running such freely available analysis tools on the Toyota ITC benchmark:</p>
<p><img src="https://user-images.githubusercontent.com/1908863/108987771-a0ea9200-76ce-11eb-86d2-e9ef1ffdeb0b.png" alt="benchmark2"></p>
<p>As expected, the scores of the freely available tools are lower than those of the commercial tools.</p>
<p>The reader should not naively assume, based on the numbers above alone, that runtime verification is simply the best program analysis approach. The best way to look at the various technologies is that they complement each other, and not that they compete with each other. For example, static analysis tools are more forgiving in terms of analyzing code that does not even compile, so they can help you find errors earlier in the process. Also, they typically analyse all your code in one run of the tool. On the other hand, dynamic analysis tools aim at very low runtime overhead, even unnoticeable if possible, at the expense of less rigorous analysis. Like dynamic analysis, runtime verification requires the program to actually execute, so it cannot analyze a program that does not compile. Also, runtime verification covers in depth only the fragment of code in your program that is actually executed, so it needs to be combined with your existing testing infrastructure (e.g., running your unit tests with the RV tool) for best results. However, unlike dynamic analysis tools, the checks that RV-Match performs are mathematically rigorous and follow the formal specification of the ISO C11 standard. For more information on the runtime verification technology underlying RV-Match, you can view <a href="https://runtimeverification.com/presentations/Technology_and_Products.pdf" target="_blank" rel="noreferrer noopener">this presentation</a>.</p>
<p>If you would like to reproduce the results of the benchmark for yourself, you can do so by executing the following commands:</p>
<blockquote>
<p>Note</p>
<p>The Toyota ITC Benchmark requires use of libraries, including libc, to run. Because our native Windows version currently does not fully support libraries, we recommend using the Linux version or a Linux-based virtual machine on Windows, including the provided Vagrant VM, to run the benchmark.</p>
</blockquote>
<pre><code>(use your package manager if not apt)
sudo apt-get install automake
git clone https://github.com/runtimeverification/toyota-itc-benchmarks
cd toyota-itc-benchmarks
git checkout fix-unintended-undefinedness
./bootstrap
CC=kcc LD=kcc CFLAGS=-flint ./configure
make -j4
</code></pre>
<p>You can then reproduce the results of any test by running the relevant program. For example, to run the first test in the second test group of tests with defects, you can run <code>./01.w_Defects/01.w_defects 002001</code>. For more information about which test groups correspond to which defect types, refer to <code>main.c</code>. If you want to check the details of our experiments involving the freely available tools described, or to redo the experiments yourself, you can find all our records and the scripts we used <a href="https://github.com/runtimeverification/evaluation/tree/master/toyota-itc-benchmark" target="_blank" rel="noreferrer noopener">on github</a>.</p>
<h2 id="fixing-bugs-in-the-benchmark">Fixing Bugs in the Benchmark</h2>
<p>Interestingly, the use of RV-Match on the Toyota ITC benchmark detected a number of flaws in the benchmark itself, both in the form of undefined behavior that was not intended by being one of the test cases of the benchmark, and in the form of tests that were intended to contain a defect but were actually correct. We have made our fixes with detailed explanations public in <a href="https://github.com/regehr/itc-benchmarks/pull/3" target="_blank" rel="noreferrer noopener">this pull request on GitHub</a>, and informed the Toyota ITC authors to fix their benchmark. If you have any comments or questions regarding any of these changes please feel free to contribute to the pull request above and/or contact us at <a href="https://runtimeverification.com/contact" target="_blank" rel="noreferrer noopener">our support page</a>.</p>
<p>Note that we used the fixed version of the benchmark in our experiments reported in the RV-Match columns in the table above. Fixing the benchmark bugs was not optional, because without some of the fixes the benchmark would not even compile with RV-Match due to constraint violation defects in the code. Unfortunately, we do not have access to the static analysis tools referenced in the ISSRE‘15 paper and the table above, so we just reproduced the results reported in the ISSRE‘15 paper for them. Because of that, it is possible that the metrics scored for the other tools may be off by some amount. If you have access to these static analysis tools and run the fixed benchmark yourself and find any inconsistencies, please contact us at <a href="https://runtimeverification.com/contact" target="_blank" rel="noreferrer noopener">our support page</a> and help us fix the numbers.</p>
</body></html></div>
        </main>

        <!-- Page ToC -->
        <div class="col-12 col-md-3 col-xl-2 py-md-3 bd-sidebar page-toc mb-3">
          
<div>
<details style="padding:0.25rem 0;;padding-left: 0px;">
            <summary class="bd-toc-link-wrapper">
              <a href="#toyota-itc-benchmark" class="bd-toc-link">Toyota ITC Benchmark</a>
              </summary>
            <div>
              <div class="bd-toc-link-wrapper" style="padding:0.25rem 0;">
              <a
                href="#the-disappearing-2014-paper"
                class="bd-toc-link"
                style="padding-left: 8px;;"
              >
                The Disappearing 2014 Paper
              </a></div><div class="bd-toc-link-wrapper" style="padding:0.25rem 0;">
              <a
                href="#running-rv-match-on-the-toyota-itc-benchmark"
                class="bd-toc-link"
                style="padding-left: 8px;;"
              >
                Running RV-Match on the Toyota ITC Benchmark
              </a></div><div class="bd-toc-link-wrapper" style="padding:0.25rem 0;">
              <a
                href="#fixing-bugs-in-the-benchmark"
                class="bd-toc-link"
                style="padding-left: 8px;;"
              >
                Fixing Bugs in the Benchmark
              </a></div>
            </div>
          </details>
        
</div>

        </div>
        <div class="btn btn-rv-blue page-toc-toggle-btn"></div>
        <!-- End Page ToC -->
      </div>
    </div>
<!-- The footer is now controlled by the k-web-theme git submodule -->
<footer id="rvsite-footer" class="app-footer text-md-left text-center">
  <div class="container">
    <div class="row align-items-center">
      <div class="col-md-4 mb-md-0 mb-4">
        <a href="https://runtimeverification.com/" target="_blank">
          <picture>
            <source
              srcset="
                https://runtimeverification.com/assets/img/rv-logo-dark.png
              "
              media="(prefers-color-scheme: dark)"
            />
            <img
              class="logo-dark"
              src="https://runtimeverification.com/assets/img/rv-logo.png"
              alt="Runtime Verification logo"
              style="height: 32px"
            /> </picture
        ></a>
        <p class="mt-2 text-md-left copyright">
          <a href="https://maps.app.goo.gl/8YhKozfmZtgzQBsH7" target="_blank"
            >202 S Broadway Ave #31, Urbana, IL</a
          >
        </p>
      </div>
      <div class="col-md-4 text-md-center mb-md-0 mb-4"></div>
      <div class="col-md-4 mb-md-0 mb-4 pl-0 text-md-right">
        <p class="copyright">2024 © all rights reserved</p>
        <span class="copyright"
          ><a href="https://runtimeverification.com/privacy-policy"
            >privacy policy</a
          >
          |
          <a href="https://runtimeverification.com/terms-of-use"
            >terms of use</a
          ></span
        >
      </div>
    </div>
  </div>
</footer>


    <script src="https://cdnjs.cloudflare.com/ajax/libs/Typist/1.2/typist.min.js"></script>
    <script src="../../assets/js/index.js"></script>
  </body>
</html>
